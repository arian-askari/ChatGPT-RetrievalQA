{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BxzvVnoB_sxM",
        "K0Viw02D_piA",
        "KFdtcqGLAqu3",
        "KNFqV9T3n3vx",
        "3LnHJEkW_0dW",
        "RuD38WaWKudG",
        "sDwllbAyMwLB",
        "FyJVGqGXOL_1",
        "BQIy_TqsXxt6",
        "Dhg5A_I0ebJ0",
        "c3P4zUchj1lf",
        "wWWT_ED2mjFK",
        "YXwv3dTnAxBv",
        "K6eWCj_fBMO7",
        "jLch2SUCC5yO",
        "3pPjwZcC_4tQ",
        "cTQdyo6yAMMG",
        "xY_XBMMoAjum",
        "Cf6Y1YcoF0Vk",
        "jhB6bxUbBoIY",
        "_orKM1FxEWWU",
        "FMNHdd1AFEEi",
        "kAFzbE5Cuxuw",
        "fYAidXXnn0IN",
        "ID5kqIQbyNpp",
        "a7AttegoyNpx",
        "77WCPjZbyNp5"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Download the data"
      ],
      "metadata": {
        "id": "BxzvVnoB_sxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/datasets/Hello-SimpleAI/HC3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnTlkIl6-n4_",
        "outputId": "53680213-9ea6-43a0-acb9-80358904beae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Failed to call git rev-parse --git-dir: exit status 128 \n",
            "Git LFS initialized.\n",
            "Cloning into 'HC3'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Total 39 (delta 0), reused 0 (delta 0), pack-reused 39\u001b[K\n",
            "Unpacking objects: 100% (39/39), 5.19 MiB | 5.32 MiB/s, done.\n",
            "Filtering content: 100% (2/2), 123.19 MiB | 32.85 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "K0Viw02D_piA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jsonlines\n",
        "import json\n",
        "import jsonlines\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "COLAB_RUN = True\n",
        "if COLAB_RUN:\n",
        "  base_path = \"./gdrive/MyDrive/ChatGPT-RetrievalQA/\"\n",
        "else:\n",
        "  base_path = \"./\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X14r2c-y_rkq",
        "outputId": "85b50422-b972-44e8-dc08-f384afc8d1d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jsonlines\n",
            "  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.8/dist-packages (from jsonlines) (22.2.0)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-3.1.0\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### normalizer for contents"
      ],
      "metadata": {
        "id": "Ddxuwiacjc4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_content(content):\n",
        "  return content.replace('\\r', '').replace('\\n', '').replace('\\t', ' ')"
      ],
      "metadata": {
        "id": "9jlzmv10jhGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset Creation"
      ],
      "metadata": {
        "id": "x_w67DCj_rJk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load all_jsonl from HC3 dataset"
      ],
      "metadata": {
        "id": "KFdtcqGLAqu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "empty_answers_ids = set([ \"17497_C_1\", \"17509_C_2\", \"17513_C_1\", \"17640_C_2\", \"17751_C_2\", \"17784_C_1\", \"17874_C_1\", \"17906_C_2\", \"18061_C_1\", \"18061_C_2\", \"18113_C_1\", \"18113_C_2\", \"18162_C_1\", \"18162_C_2\", \"18253_C_1\", \"23832_C_0\", \"24020_C_0\", \"24283_C_1\"])\n",
        "all_jsonl = []\n",
        "qrels_all_c = {}\n",
        "qrels_all_h = {}\n",
        "all_chatgpt_answerids = {}\n",
        "all_human_answerids = {}\n",
        "query_dict = {}\n",
        "question_id = -1\n",
        "chatgpt_answer_id_format = \"{}_C_{}\"#\"{question_id}_C_{chatgpt_answer_id}\"\n",
        "human_answer_id_format = \"{}_H_{}\"#\"{question_id}_H_{human_answer_id}\"\n",
        "with jsonlines.open('HC3/all.jsonl') as reader:\n",
        "  for obj in reader:\n",
        "    #assining id to question text\n",
        "    question_id+=1\n",
        "    obj[\"question_id\"] = question_id\n",
        "    query_dict[question_id]  = obj[\"question\"]\n",
        "    if question_id not in qrels_all_c:\n",
        "      qrels_all_c[question_id] = []\n",
        "      qrels_all_h[question_id] = []\n",
        "    #assigning id to chatgpt answers\n",
        "    obj[\"chatgpt_answers_ids\"] = []\n",
        "    chatgpt_answer_id = -1\n",
        "    for chatgpt_answer in obj[\"chatgpt_answers\"]:\n",
        "      chatgpt_answer_id+=1\n",
        "      chatgpt_answer_id_str = chatgpt_answer_id_format.format(question_id, chatgpt_answer_id)\n",
        "      if chatgpt_answer_id_str in empty_answers_ids:\n",
        "        del obj[\"chatgpt_answers\"][chatgpt_answer_id]\n",
        "      else:\n",
        "        obj[\"chatgpt_answers_ids\"].append(chatgpt_answer_id_str)\n",
        "        qrels_all_c[question_id].append(chatgpt_answer_id_str)\n",
        "        all_chatgpt_answerids[chatgpt_answer_id_str] = chatgpt_answer\n",
        "\n",
        "    #assining id to human answers\n",
        "    obj[\"human_answers_ids\"] = []\n",
        "    human_answer_id = -1\n",
        "    for human_answer in obj[\"human_answers\"]:\n",
        "      human_answer_id+=1\n",
        "      human_answer_id_str = human_answer_id_format.format(question_id, human_answer_id)\n",
        "      obj[\"human_answers_ids\"].append(human_answer_id_str)\n",
        "      qrels_all_h[question_id].append(human_answer_id_str)\n",
        "      all_human_answerids[human_answer_id_str] = human_answer\n",
        "    # print(obj)\n",
        "    all_jsonl.append(obj)"
      ],
      "metadata": {
        "id": "TF_o45l_AsBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fixing an issue in the current version of HC3 dataset! \n",
        "There are 18 responses by ChatGPT that are empty in the current version of HC3 dataset. \n",
        "The ids of these answer after we assign ids to chatGPTresponses are: [17497_C_1, 17509_C_2, 17513_C_1, 17640_C_2, 17751_C_2, 17784_C_1, 17874_C_1, 17906_C_2, 18061_C_1, 18061_C_2, 18113_C_1, 18113_C_2, 18162_C_1, 18162_C_2, 18253_C_1, 23832_C_0, 24020_C_0, 24283_C_1]\n",
        "\n",
        "For fixing this issue, we remove those responses that their id suffix is C_1 or C_2 (in the above cell we removed them) because it means that there is at least one response by chatGPT for them. However, two answers (**24020_C_0, 23832_C_0**) are the only response for the question and they are empty! So we give these question to ChatGPT and insert the answer of ChatGPT to these two answer manually!"
      ],
      "metadata": {
        "id": "KNFqV9T3n3vx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for empty_answer_id in empty_answers_ids:\n",
        "  if empty_answer_id in all_chatgpt_answerids:\n",
        "    print(\"deleting empty_answer_id: \", empty_answer_id)\n",
        "    del all_chatgpt_answerids[empty_answer_id]"
      ],
      "metadata": {
        "id": "LS7QRQv3sV7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('question for 24020_C_0: ', query_dict[24020])\n",
        "print('question for 23832_C_0: ', query_dict[23832])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyp008LnljCW",
        "outputId": "02cbdad0-8af8-4b0e-f3ab-87bfa17202c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question for 24020_C_0:  How to get a sure cure of acne ?hi, if you have been to the doctors before to get something checked out and they tell you that you have something similar to acne what can you ask for to get rid of them ?\n",
            "question for 23832_C_0:  Kidney infection, weird twinges in bladder and uterus, lower back pain, fibroid in uterus. Bladder recovering from the infection?Hi, I have just had a kidney infection. No fever now and it seems to have cleared. However, I am feeling very weird twinges in my bladder or uterus . Not really a pain, although I do have lower back pain. Is it just the bladder recovering from the infection? I do have a fibroid in my uterus,I am five years into menopause.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_chatgpt_answerids['24020_C_0'] = \"Acne is a common skin condition that affects many people, and there is no one-size-fits-all cure for it. However, there are several treatments that can help reduce its severity and improve the appearance of your skin. To get a sure cure for acne, you can consider the following steps: Consult a dermatologist: A dermatologist can diagnose your skin condition and determine the best treatment plan for you based on the type and severity of your acne. Use topical treatments: Topical creams and gels that contain active ingredients such as benzoyl peroxide, salicylic acid, and retinoids can help unclog pores and reduce inflammation. Take oral medications: If your acne is severe, your dermatologist may prescribe oral antibiotics to help reduce bacteria and inflammation. Consider light and laser therapies: Light and laser therapies, such as blue light therapy or photodynamic therapy, can help kill acne-causing bacteria and reduce inflammation. Maintain a healthy lifestyle: Eating a healthy diet, getting enough sleep, and reducing stress can also help improve your skin and prevent future breakouts. It's important to follow your dermatologist's recommendations and be patient, as some treatments may take several weeks or months to produce noticeable results.\"\n",
        "all_chatgpt_answerids['23832_C_0'] = \"It's always best to seek the advice of a doctor to get a proper diagnosis, but the symptoms you are describing could indicate a number of conditions. The twinges and lower back pain could be related to the fibroid in your uterus, which is a common condition. The fibroid could be pressing on the nerves in your back and causing pain. The bladder twinges could be related to the recent kidney infection, and your bladder could still be recovering from the infection. It's possible that the twinges could also be related to other factors such as bladder problems or even menopause-related changes. I would recommend visiting your doctor for an examination and to discuss your symptoms. Your doctor may want to run some tests to determine the cause of your symptoms and determine the best course of treatment.\""
      ],
      "metadata": {
        "id": "ZRLEdU-1rU4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('len all_jsonl[24020][\"chatgpt_answers\"]', len(all_jsonl[24020][\"chatgpt_answers\"]))\n",
        "all_jsonl[24020][\"chatgpt_answers\"].append(all_chatgpt_answerids['24020_C_0'])\n",
        "all_jsonl[24020][\"chatgpt_answers_ids\"].append('24020_C_0')\n",
        "print('len all_jsonl[23832][\"chatgpt_answers\"]', len(all_jsonl[23832][\"chatgpt_answers\"]))\n",
        "all_jsonl[23832][\"chatgpt_answers\"].append(all_chatgpt_answerids['23832_C_0'])\n",
        "all_jsonl[23832][\"chatgpt_answers_ids\"].append('23832_C_0')\n",
        "\n",
        "print('len all_jsonl[24020][\"chatgpt_answers\"]', len(all_jsonl[24020][\"chatgpt_answers\"]))\n",
        "print('len all_jsonl[23832][\"chatgpt_answers\"]', len(all_jsonl[23832][\"chatgpt_answers\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apQG-67aBEIL",
        "outputId": "0e99bbe5-1427-448d-a88c-4c66449db579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len all_jsonl[24020][\"chatgpt_answers\"] 0\n",
            "len all_jsonl[23832][\"chatgpt_answers\"] 0\n",
            "len all_jsonl[24020][\"chatgpt_answers\"] 1\n",
            "len all_jsonl[23832][\"chatgpt_answers\"] 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all_jsonl[20]"
      ],
      "metadata": {
        "id": "FLJqEtfLFojj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Collection-H (Colletion of responses that are produced by humans)"
      ],
      "metadata": {
        "id": "3LnHJEkW_0dW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Collection-H\n",
        "collection_h = []\n",
        "output_path = base_path + \"collection_h.tsv\"\n",
        "collection_line_format = \"{id}\\t{content}\\n\"\n",
        "for obj in all_jsonl:\n",
        "  for answer, answer_id in zip(obj[\"human_answers\"], obj[\"human_answers_ids\"]):\n",
        "    collection_h.append(collection_line_format.format(id= answer_id, content= normalize_content(answer)))\n",
        "f_w = open(output_path, \"w+\")\n",
        "f_w.write(\"\".join(collection_h))\n",
        "f_w.close()"
      ],
      "metadata": {
        "id": "zgKGrvO-b-cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Collection-C (Colletion of responses that are produced by ChatGPT)"
      ],
      "metadata": {
        "id": "RuD38WaWKudG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Collection-H\n",
        "collection_c = []\n",
        "output_path = base_path + \"collection_c.tsv\"\n",
        "collection_line_format = \"{id}\\t{content}\\n\"\n",
        "for obj in all_jsonl:\n",
        "  for answer, answer_id in zip(obj[\"chatgpt_answers\"], obj[\"chatgpt_answers_ids\"]):\n",
        "    collection_c.append(collection_line_format.format(id= answer_id, content= normalize_content(answer)))\n",
        "f_w = open(output_path, \"w+\")\n",
        "f_w.write(\"\".join(collection_c))\n",
        "f_w.close()"
      ],
      "metadata": {
        "id": "0dmehQpeKudJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat ./gdrive/MyDrive/ChatGPT-RetrievalQA/collection_c.tsv | grep 24020_C_0"
      ],
      "metadata": {
        "id": "09seQe_rB1_w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ad56d7d-630c-4540-817a-55cbce85fb80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24020_C_0\tAcne is a common skin condition that affects many people, and there is no one-size-fits-all cure for it. However, there are several treatments that can help reduce its severity and improve the appearance of your skin. To get a sure cure for acne, you can consider the following steps: Consult a dermatologist: A dermatologist can diagnose your skin condition and determine the best treatment plan for you based on the type and severity of your acne. Use topical treatments: Topical creams and gels that contain active ingredients such as benzoyl peroxide, salicylic acid, and retinoids can help unclog pores and reduce inflammation. Take oral medications: If your acne is severe, your dermatologist may prescribe oral antibiotics to help reduce bacteria and inflammation. Consider light and laser therapies: Light and laser therapies, such as blue light therapy or photodynamic therapy, can help kill acne-causing bacteria and reduce inflammation. Maintain a healthy lifestyle: Eating a healthy diet, getting enough sleep, and reducing stress can also help improve your skin and prevent future breakouts. It's important to follow your dermatologist's recommendations and be patient, as some treatments may take several weeks or months to produce noticeable results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Queries"
      ],
      "metadata": {
        "id": "sDwllbAyMwLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#queries.tsv\n",
        "queries = []\n",
        "output_path = base_path + \"queries.tsv\"\n",
        "queries_line_format = \"{id}\\t{content}\\n\"\n",
        "for obj in all_jsonl:\n",
        "  question = obj[\"question\"]\n",
        "  question_id = obj[\"question_id\"]\n",
        "  queries.append(queries_line_format.format(id= question_id, content= normalize_content(question)))\n",
        "f_w = open(output_path, \"w+\")\n",
        "f_w.write(\"\".join(queries))\n",
        "f_w.close()"
      ],
      "metadata": {
        "id": "gUC2FpI0MxdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split based on domain to train/valid/test (keep question ids as representation of train/valid/test set)"
      ],
      "metadata": {
        "id": "FyJVGqGXOL_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "all_questions = len(queries)\n",
        "all_domains = list(set([obj[\"source\"] for obj in all_jsonl]))\n",
        "cnt_of_questions_per_domain = dict(Counter([obj[\"source\"] for obj in all_jsonl]))\n",
        "print(\"# of all_questions: \", all_questions)\n",
        "print(\"all_domains: \", all_domains)\n",
        "print(\"cnt_of_questions_per_domain: \", cnt_of_questions_per_domain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF_KRdUUOUKi",
        "outputId": "03996251-ac2c-4e88-bd54-596d57ea2263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of all_questions:  24322\n",
            "all_domains:  ['wiki_csai', 'medicine', 'reddit_eli5', 'finance', 'open_qa']\n",
            "cnt_of_questions_per_domain:  {'reddit_eli5': 17112, 'open_qa': 1187, 'wiki_csai': 842, 'finance': 3933, 'medicine': 1248}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "question_ids_all and question_ids_per_domain"
      ],
      "metadata": {
        "id": "dU3CsCXkVJR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question_ids_all = []\n",
        "question_ids_per_domain = {}\n",
        "for obj in all_jsonl:\n",
        "  domain = obj[\"source\"]\n",
        "  question_id = obj[\"question_id\"]\n",
        "  question_ids_all.append(question_id)\n",
        "  if domain not in question_ids_per_domain:\n",
        "    question_ids_per_domain[domain] = []\n",
        "  question_ids_per_domain[domain].append(question_id)\n",
        "# check question ids count per domain is correct\n",
        "for key in question_ids_per_domain.keys():\n",
        "  assert len(question_ids_per_domain[key]) == cnt_of_questions_per_domain[key]"
      ],
      "metadata": {
        "id": "XfEHkJHWVH_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percent_per_split = {\"train\": 0.69, \"test\": 0.285, \"valid\": 0.025}\n",
        "each_split_exact_size = {\"train\": 0, \"test\": 0, \"valid\": 0}\n",
        "splitsize_questions_per_domain = {}\n",
        "split_questions_ids_per_domain = {}\n",
        "split_questions_ids_all = {\"train\": [], \"valid\":[], \"test\":[]}\n",
        "\n",
        "for domain, number_of_questions in cnt_of_questions_per_domain.items():\n",
        "  splitsize_questions_per_domain[domain] = {}\n",
        "  \n",
        "  testset_number_of_questions = int(percent_per_split['test'] * number_of_questions)\n",
        "  splitsize_questions_per_domain[domain][\"test\"] = testset_number_of_questions\n",
        "\n",
        "  validset_number_of_questions = int(percent_per_split['valid'] * number_of_questions)\n",
        "  splitsize_questions_per_domain[domain][\"valid\"] = validset_number_of_questions\n",
        "\n",
        "  trainset_number_of_questions = number_of_questions - (testset_number_of_questions + validset_number_of_questions)\n",
        "  assert trainset_number_of_questions + validset_number_of_questions + testset_number_of_questions == number_of_questions\n",
        "  splitsize_questions_per_domain[domain][\"train\"] = trainset_number_of_questions\n",
        "  \n",
        "  each_split_exact_size[\"train\"] += trainset_number_of_questions\n",
        "  each_split_exact_size[\"valid\"] += validset_number_of_questions\n",
        "  each_split_exact_size[\"test\"] += testset_number_of_questions\n",
        "\n",
        "  split_questions_ids_per_domain[domain] = {}\n",
        "\n",
        "  split_questions_ids_per_domain[domain][\"train\"] = question_ids_per_domain[domain][0:trainset_number_of_questions]\n",
        "  split_questions_ids_per_domain[domain][\"valid\"] = question_ids_per_domain[domain][trainset_number_of_questions:trainset_number_of_questions+validset_number_of_questions]\n",
        "  split_questions_ids_per_domain[domain][\"test\"] = question_ids_per_domain[domain][trainset_number_of_questions+validset_number_of_questions:number_of_questions]\n",
        "  \n",
        "  split_questions_ids_all[\"train\"] = split_questions_ids_all[\"train\"] + split_questions_ids_per_domain[domain][\"train\"] \n",
        "  split_questions_ids_all[\"valid\"] = split_questions_ids_all[\"valid\"] + split_questions_ids_per_domain[domain][\"valid\"] \n",
        "  split_questions_ids_all[\"test\"] = split_questions_ids_all[\"test\"] + split_questions_ids_per_domain[domain][\"test\"] \n",
        "  \n",
        "print(\"number of questions for train/test/valid per domain: \", splitsize_questions_per_domain)\n",
        "print(\"number of questions for train/test/valid for all: \", each_split_exact_size)\n",
        "assert (each_split_exact_size[\"train\"] + each_split_exact_size[\"valid\"] + each_split_exact_size[\"test\"]) == all_questions\n",
        "\n",
        "for domain, splits in split_questions_ids_per_domain.items():\n",
        "  for split in splits:\n",
        "    assert len(split_questions_ids_per_domain[domain][split]) == splitsize_questions_per_domain[domain][split]\n",
        "\n",
        "assert len(split_questions_ids_all[\"train\"] + split_questions_ids_all[\"valid\"] + split_questions_ids_all[\"test\"]) == all_questions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eeg-Wr1SPY71",
        "outputId": "51f28b75-90d2-416b-de04-73aa0c27b733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of questions for train/test/valid per domain:  {'reddit_eli5': {'test': 4876, 'valid': 427, 'train': 11809}, 'open_qa': {'test': 338, 'valid': 29, 'train': 820}, 'wiki_csai': {'test': 239, 'valid': 21, 'train': 582}, 'finance': {'test': 1120, 'valid': 98, 'train': 2715}, 'medicine': {'test': 355, 'valid': 31, 'train': 862}}\n",
            "number of questions for train/test/valid for all:  {'train': 16788, 'test': 6928, 'valid': 606}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "re-check (besides assert) to see what is going in the data, e.g., for reddit_eli5 source, in train set, we should have 11809 questions. Let's check it and being sure:"
      ],
      "metadata": {
        "id": "as9aVntKXahf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"reddit_eli5, train size: \", len(split_questions_ids_per_domain[\"reddit_eli5\"][\"train\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXocSObRXODX",
        "outputId": "4c2ef11d-4a3e-47f7-b081-a22ec66bb23c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reddit_eli5, train size:  11809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data split size per source (domain) and per split (train/valid/test)\n",
        "##### **Number of questions for train/test/valid per domain:**  {'reddit_eli5': {'test': 4876, 'valid': 427, 'train': 11809}, 'open_qa': {'test': 338, 'valid': 29, 'train': 820}, 'wiki_csai': {'test': 239, 'valid': 21, 'train': 582}, 'finance': {'test': 1120, 'valid': 98, 'train': 2715}, 'medicine': {'test': 355, 'valid': 31, 'train': 862}}\n",
        "#### **Number of questions for train/test/valid for all:**  {'train': 16788, 'test': 6928, 'valid': 606}\n"
      ],
      "metadata": {
        "id": "rKPguUflYrpO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### qrels_h_{train/valid/test}.tsv"
      ],
      "metadata": {
        "id": "BQIy_TqsXxt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#qrels_h_train.tsv\n",
        "qrels_lines = []\n",
        "qrel_line_format = \"{qid}\t0\t{did}\t1\\n\"\n",
        "for question_id in split_questions_ids_all[\"train\"]:\n",
        "  rel_docs = qrels_all_h[question_id]\n",
        "  for did in rel_docs:\n",
        "    qrels_lines.append(qrel_line_format.format(qid = question_id, did = did))\n",
        "output_path = base_path + \"qrels_h_train.tsv\"\n",
        "f_w = open(output_path, \"w+\")\n",
        "f_w.write(\"\".join(qrels_lines))\n",
        "f_w.close()\n",
        "print(\"line cnt: \", len(qrels_lines))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43JBOi4sa6uL",
        "outputId": "78b5960a-8bb2-495a-d1a7-e71c81ec6d44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "line cnt:  40406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#qrels_h_valid.tsv\n",
        "qrels_lines = []\n",
        "qrel_line_format = \"{qid}\t0\t{did}\t1\\n\"\n",
        "for question_id in split_questions_ids_all[\"valid\"]:\n",
        "  rel_docs = qrels_all_h[question_id]\n",
        "  for did in rel_docs:\n",
        "    qrels_lines.append(qrel_line_format.format(qid = question_id, did = did))\n",
        "output_path = base_path + \"qrels_h_valid.tsv\"\n",
        "f_w = open(output_path, \"w+\")\n",
        "f_w.write(\"\".join(qrels_lines))\n",
        "f_w.close()\n",
        "print(\"line cnt: \", len(qrels_lines))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD93OFNcb9ad",
        "outputId": "68e79c67-a20d-493a-b318-a7d278b12d4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "line cnt:  1460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#qrels_h_test.tsv\n",
        "qrels_lines = []\n",
        "qrel_line_format = \"{qid}\t0\t{did}\t1\\n\"\n",
        "for question_id in split_questions_ids_all[\"test\"]:\n",
        "  rel_docs = qrels_all_h[question_id]\n",
        "  for did in rel_docs:\n",
        "    qrels_lines.append(qrel_line_format.format(qid = question_id, did = did))\n",
        "output_path = base_path + \"qrels_h_test.tsv\"\n",
        "f_w = open(output_path, \"w+\")\n",
        "f_w.write(\"\".join(qrels_lines))\n",
        "f_w.close()\n",
        "print(\"line cnt: \", len(qrels_lines))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBcGP7gjb_nF",
        "outputId": "b0eef7cd-a6df-4f0b-c12c-e1a6b8d271b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "line cnt:  16680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### qrels_c_{train/valid/test}.tsv"
      ],
      "metadata": {
        "id": "Dhg5A_I0ebJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#qrels_c_train.tsv\n",
        "qrels_lines = []\n",
        "qrel_line_format = \"{qid}\t0\t{did}\t1\\n\"\n",
        "for question_id in split_questions_ids_all[\"train\"]:\n",
        "  rel_docs = qrels_all_c[question_id]\n",
        "  for did in rel_docs:\n",
        "    qrels_lines.append(qrel_line_format.format(qid = question_id, did = did))\n",
        "output_path = base_path + \"qrels_c_train.tsv\"\n",
        "f_w = open(output_path, \"w+\")\n",
        "f_w.write(\"\".join(qrels_lines))\n",
        "f_w.close()\n",
        "print(\"line cnt: \", len(qrels_lines))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ead1f6-ef6a-47d4-a706-8ad082e57ce7",
        "id": "Hh4F2CR_ebJ1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "line cnt:  18452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#qrels_c_valid.tsv\n",
        "qrels_lines = []\n",
        "qrel_line_format = \"{qid}\t0\t{did}\t1\\n\"\n",
        "for question_id in split_questions_ids_all[\"valid\"]:\n",
        "  rel_docs = qrels_all_c[question_id]\n",
        "  for did in rel_docs:\n",
        "    qrels_lines.append(qrel_line_format.format(qid = question_id, did = did))\n",
        "output_path = base_path + \"qrels_c_valid.tsv\"\n",
        "f_w = open(output_path, \"w+\")\n",
        "f_w.write(\"\".join(qrels_lines))\n",
        "f_w.close()\n",
        "print(\"line cnt: \", len(qrels_lines))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVWOWJnfh5PW",
        "outputId": "c08b01a9-dee3-4155-b89d-7a374bb2e183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "line cnt:  672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#qrels_c_test.tsv\n",
        "qrels_lines = []\n",
        "qrel_line_format = \"{qid}\t0\t{did}\t1\\n\"\n",
        "for question_id in split_questions_ids_all[\"test\"]:\n",
        "  rel_docs = qrels_all_c[question_id]\n",
        "  for did in rel_docs:\n",
        "    qrels_lines.append(qrel_line_format.format(qid = question_id, did = did))\n",
        "output_path = base_path + \"qrels_c_test.tsv\"\n",
        "f_w = open(output_path, \"w+\")\n",
        "f_w.write(\"\".join(qrels_lines))\n",
        "f_w.close()\n",
        "print(\"line cnt: \", len(qrels_lines))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsv9MD4Xh5he",
        "outputId": "020fcbe0-0e7c-472f-818a-a312c5566393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "line cnt:  7756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### collectionandqueries.zip"
      ],
      "metadata": {
        "id": "c3P4zUchj1lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r ./gdrive/MyDrive/ChatGPT-RetrievalQA/collectionandqueries.zip ./gdrive/MyDrive/ChatGPT-RetrievalQA/qrels_c_test.tsv ./gdrive/MyDrive/ChatGPT-RetrievalQA/qrels_c_valid.tsv ./gdrive/MyDrive/ChatGPT-RetrievalQA/qrels_c_train.tsv ./gdrive/MyDrive/ChatGPT-RetrievalQA/qrels_h_test.tsv ./gdrive/MyDrive/ChatGPT-RetrievalQA/qrels_h_valid.tsv ./gdrive/MyDrive/ChatGPT-RetrievalQA/qrels_h_train.tsv ./gdrive/MyDrive/ChatGPT-RetrievalQA/queries.tsv ./gdrive/MyDrive/ChatGPT-RetrievalQA/collection_c.tsv ./gdrive/MyDrive/ChatGPT-RetrievalQA/collection_h.tsv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ8D60_Uj2LV",
        "outputId": "23161d92-3208-4077-8fd4-5b55c8abbf32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: gdrive/MyDrive/ChatGPT-RetrievalQA/collection_c.tsv (deflated 70%)\n",
            "updating: gdrive/MyDrive/ChatGPT-RetrievalQA/collection_h.tsv (deflated 63%)\n",
            "updating: gdrive/MyDrive/ChatGPT-RetrievalQA/qrels_c_test.tsv (deflated 77%)\n",
            "updating: gdrive/MyDrive/ChatGPT-RetrievalQA/qrels_c_train.tsv (deflated 74%)\n",
            "updating: gdrive/MyDrive/ChatGPT-RetrievalQA/qrels_c_valid.tsv (deflated 80%)\n",
            "updating: gdrive/MyDrive/ChatGPT-RetrievalQA/qrels_h_test.tsv (deflated 86%)\n",
            "updating: gdrive/MyDrive/ChatGPT-RetrievalQA/qrels_h_train.tsv (deflated 84%)\n",
            "updating: gdrive/MyDrive/ChatGPT-RetrievalQA/qrels_h_valid.tsv (deflated 85%)\n",
            "updating: gdrive/MyDrive/ChatGPT-RetrievalQA/queries.tsv (deflated 65%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-H Triples (tsv: query, positive passage, negative passage)"
      ],
      "metadata": {
        "id": "wWWT_ED2mjFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_content(content):\n",
        "  return content.replace('\\r', '').replace('\\n', '').replace('\\t', ' ')\n",
        "\n",
        "import random\n",
        "import tqdm\n",
        "random.seed(42)\n",
        "negative_docs_size = 1000\n",
        "output_path = base_path + \"train_h_triples.tsv\"\n",
        "output_path_qidpid = base_path + \"train_h_qidpidtriples.tsv\"\n",
        "output_line_format = \"{query}\\t{positive_content}\\t{neg_content}\\n\"\n",
        "output_line_format_qidpid = \"{qid}\\t{positive_id}\\t{neg_id}\\n\"\n",
        "output_lines = []\n",
        "all_human_answerids_list = list(all_human_answerids.keys())\n",
        "# all_chatgpt_answerids = []\n",
        "# all_human_answerids = []\n",
        "f_w = open(output_path, \"w+\")\n",
        "f_w_qidpid = open(output_path_qidpid, \"w+\")\n",
        "for question_id in tqdm.tqdm(split_questions_ids_all[\"train\"]):\n",
        "  rel_docs = qrels_all_h[question_id]\n",
        "  rel_docs_set = set(rel_docs) # for efficiency! check item not in rel_docs_set is O(1)\n",
        "  # candidate_negs = [item for item in all_human_answerids if item not in rel_docs_set]\n",
        "  # neg_ids = random.sample(candidate_negs, negative_docs_size+10) \n",
        "  neg_ids = random.sample(all_human_answerids_list, negative_docs_size+10) # 10 is added just to being sure that we will have 1k negatives. because it is possible to pos_id selected randomly and we want being able to skip that while have 1k negatives\n",
        "  neg_ids_added = 0\n",
        "  for pos_id in rel_docs:\n",
        "    for neg_id in neg_ids:\n",
        "      if neg_id == pos_id: continue\n",
        "      line = output_line_format.format(\n",
        "          query = normalize_content(query_dict[question_id]),\n",
        "          positive_content = normalize_content(all_human_answerids[pos_id]),\n",
        "          neg_content = normalize_content(all_human_answerids[neg_id]),\n",
        "      )\n",
        "      # output_lines.append(line)\n",
        "      f_w.write(line)\n",
        "\n",
        "      line_qidpid = output_line_format_qidpid.format(\n",
        "          qid = question_id,\n",
        "          positive_id = pos_id,\n",
        "          neg_id = neg_id,\n",
        "      )\n",
        "      f_w_qidpid.write(line_qidpid)\n",
        "      neg_ids_added+=1\n",
        "      if neg_ids_added==negative_docs_size:\n",
        "        break\n",
        "      assert pos_id != neg_id\n",
        "f_w.close()\n",
        "f_w_qidpid.close()\n",
        "print(\"line cnt: \", len(output_lines))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvDGRgSTmkdT",
        "outputId": "9aa4a0ff-133d-4964-b95a-be552019cd60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16788/16788 [13:01<00:00, 21.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "line cnt:  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Valid-H Triples (tsv: query, positive passage, negative passage)"
      ],
      "metadata": {
        "id": "YXwv3dTnAxBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_content(content):\n",
        "  return content.replace('\\r', '').replace('\\n', '').replace('\\t', ' ')\n",
        "\n",
        "import random\n",
        "import tqdm\n",
        "random.seed(42)\n",
        "negative_docs_size = 1000\n",
        "output_path = base_path + \"valid_h_triples.tsv\"\n",
        "output_path_qidpid = base_path + \"valid_h_qidpidtriples.tsv\"\n",
        "output_line_format = \"{query}\\t{positive_content}\\t{neg_content}\\n\"\n",
        "output_line_format_qidpid = \"{qid}\\t{positive_id}\\t{neg_id}\\n\"\n",
        "output_lines = []\n",
        "all_human_answerids_list = list(all_human_answerids.keys())\n",
        "# all_chatgpt_answerids = []\n",
        "# all_human_answerids = []\n",
        "f_w = open(output_path, \"w+\")\n",
        "f_w_qidpid = open(output_path_qidpid, \"w+\")\n",
        "for question_id in tqdm.tqdm(split_questions_ids_all[\"valid\"]):\n",
        "  rel_docs = qrels_all_h[question_id]\n",
        "  rel_docs_set = set(rel_docs) # for efficiency! check item not in rel_docs_set is O(1)\n",
        "  # candidate_negs = [item for item in all_human_answerids if item not in rel_docs_set]\n",
        "  # neg_ids = random.sample(candidate_negs, negative_docs_size+10) \n",
        "  neg_ids = random.sample(all_human_answerids_list, negative_docs_size+10) # 10 is added just to being sure that we will have 1k negatives. because it is possible to pos_id selected randomly and we want being able to skip that while have 1k negatives\n",
        "  neg_ids_added = 0\n",
        "  for pos_id in rel_docs:\n",
        "    for neg_id in neg_ids:\n",
        "      if neg_id == pos_id: continue\n",
        "      line = output_line_format.format(\n",
        "          query = normalize_content(query_dict[question_id]),\n",
        "          positive_content = normalize_content(all_human_answerids[pos_id]),\n",
        "          neg_content = normalize_content(all_human_answerids[neg_id]),\n",
        "      )\n",
        "      # output_lines.append(line)\n",
        "      f_w.write(line)\n",
        "\n",
        "      line_qidpid = output_line_format_qidpid.format(\n",
        "          qid = question_id,\n",
        "          positive_id = pos_id,\n",
        "          neg_id = neg_id,\n",
        "      )\n",
        "      f_w_qidpid.write(line_qidpid)\n",
        "      neg_ids_added+=1\n",
        "      if neg_ids_added==negative_docs_size:\n",
        "        break\n",
        "      assert pos_id != neg_id\n",
        "f_w.close()\n",
        "f_w_qidpid.close()\n",
        "print(\"line cnt: \", len(output_lines))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17fbb711-8aa7-4d0f-9a7d-bbd0a165894e",
        "id": "K1K9AUX4AxBy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 606/606 [00:33<00:00, 17.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "line cnt:  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QzvEQ2kABMHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-C Triples (tsv: query, positive passage, negative passage)"
      ],
      "metadata": {
        "id": "K6eWCj_fBMO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_content(content):\n",
        "  return content.replace('\\r', '').replace('\\n', '').replace('\\t', ' ')\n",
        "\n",
        "import random\n",
        "import tqdm\n",
        "random.seed(42)\n",
        "negative_docs_size = 1000\n",
        "output_path = base_path + \"train_c_triples.tsv\"\n",
        "output_path_qidpid = base_path + \"train_c_qidpidtriples.tsv\"\n",
        "output_line_format = \"{query}\\t{positive_content}\\t{neg_content}\\n\"\n",
        "output_line_format_qidpid = \"{qid}\\t{positive_id}\\t{neg_id}\\n\"\n",
        "output_lines = []\n",
        "# all_human_answerids_list = list(all_human_answerids.keys())\n",
        "all_chatgpt_answerids_list = list(all_chatgpt_answerids.keys())\n",
        "# all_chatgpt_answerids = []\n",
        "# all_human_answerids = []\n",
        "f_w = open(output_path, \"w+\")\n",
        "f_w_qidpid = open(output_path_qidpid, \"w+\")\n",
        "for question_id in tqdm.tqdm(split_questions_ids_all[\"train\"]):\n",
        "  rel_docs = qrels_all_c[question_id]\n",
        "  rel_docs_set = set(rel_docs) # for efficiency! check item not in rel_docs_set is O(1)\n",
        "  # candidate_negs = [item for item in all_human_answerids if item not in rel_docs_set]\n",
        "  # neg_ids = random.sample(candidate_negs, negative_docs_size+10) \n",
        "  neg_ids = random.sample(all_chatgpt_answerids_list, negative_docs_size+10) # 10 is added just to being sure that we will have 1k negatives. because it is possible to pos_id selected randomly and we want being able to skip that while have 1k negatives\n",
        "  neg_ids_added = 0\n",
        "  for pos_id in rel_docs:\n",
        "    for neg_id in neg_ids:\n",
        "      if neg_id == pos_id: continue\n",
        "      line = output_line_format.format(\n",
        "          query = normalize_content(query_dict[question_id]),\n",
        "          positive_content = normalize_content(all_chatgpt_answerids[pos_id]),\n",
        "          neg_content = normalize_content(all_chatgpt_answerids[neg_id]),\n",
        "      )\n",
        "      # output_lines.append(line)\n",
        "      f_w.write(line)\n",
        "\n",
        "      line_qidpid = output_line_format_qidpid.format(\n",
        "          qid = question_id,\n",
        "          positive_id = pos_id,\n",
        "          neg_id = neg_id,\n",
        "      )\n",
        "      f_w_qidpid.write(line_qidpid)\n",
        "      neg_ids_added+=1\n",
        "      if neg_ids_added==negative_docs_size:\n",
        "        break\n",
        "      assert pos_id != neg_id\n",
        "f_w.close()\n",
        "f_w_qidpid.close()\n",
        "print(\"line cnt: \", len(output_lines))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb5e7f99-5be8-4d1a-805e-098a1c788c29",
        "id": "6Ix0SjVoBMO9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16788/16788 [10:11<00:00, 27.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "line cnt:  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Valid-C Triples (tsv: query, positive passage, negative passage)"
      ],
      "metadata": {
        "id": "jLch2SUCC5yO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_content(content):\n",
        "  return content.replace('\\r', '').replace('\\n', '').replace('\\t', ' ')\n",
        "\n",
        "import random\n",
        "import tqdm\n",
        "random.seed(42)\n",
        "negative_docs_size = 1000\n",
        "output_path = base_path + \"valid_c_triples.tsv\"\n",
        "output_path_qidpid = base_path + \"valid_c_qidpidtriples.tsv\"\n",
        "output_line_format = \"{query}\\t{positive_content}\\t{neg_content}\\n\"\n",
        "output_line_format_qidpid = \"{qid}\\t{positive_id}\\t{neg_id}\\n\"\n",
        "output_lines = []\n",
        "# all_human_answerids_list = list(all_human_answerids.keys())\n",
        "all_chatgpt_answerids_list = list(all_chatgpt_answerids.keys())\n",
        "# all_chatgpt_answerids = []\n",
        "# all_human_answerids = []\n",
        "f_w = open(output_path, \"w+\")\n",
        "f_w_qidpid = open(output_path_qidpid, \"w+\")\n",
        "for question_id in tqdm.tqdm(split_questions_ids_all[\"valid\"]):\n",
        "  rel_docs = qrels_all_c[question_id]\n",
        "  rel_docs_set = set(rel_docs) # for efficiency! check item not in rel_docs_set is O(1)\n",
        "  # candidate_negs = [item for item in all_human_answerids if item not in rel_docs_set]\n",
        "  # neg_ids = random.sample(candidate_negs, negative_docs_size+10) \n",
        "  neg_ids = random.sample(all_chatgpt_answerids_list, negative_docs_size+10) # 10 is added just to being sure that we will have 1k negatives. because it is possible to pos_id selected randomly and we want being able to skip that while have 1k negatives\n",
        "  neg_ids_added = 0\n",
        "  for pos_id in rel_docs:\n",
        "    for neg_id in neg_ids:\n",
        "      if neg_id == pos_id: continue\n",
        "      line = output_line_format.format(\n",
        "          query = normalize_content(query_dict[question_id]),\n",
        "          positive_content = normalize_content(all_chatgpt_answerids[pos_id]),\n",
        "          neg_content = normalize_content(all_chatgpt_answerids[neg_id]),\n",
        "      )\n",
        "      # output_lines.append(line)\n",
        "      f_w.write(line)\n",
        "\n",
        "      line_qidpid = output_line_format_qidpid.format(\n",
        "          qid = question_id,\n",
        "          positive_id = pos_id,\n",
        "          neg_id = neg_id,\n",
        "      )\n",
        "      f_w_qidpid.write(line_qidpid)\n",
        "      neg_ids_added+=1\n",
        "      if neg_ids_added==negative_docs_size:\n",
        "        break\n",
        "      assert pos_id != neg_id\n",
        "f_w.close()\n",
        "f_w_qidpid.close()\n",
        "print(\"line cnt: \", len(output_lines))"
      ],
      "metadata": {
        "id": "0dOTg7e1C5yQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bd67b4b-a011-4d53-d213-e3a58fe2e5d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 606/606 [00:22<00:00, 27.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "line cnt:  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Re-ranking\n",
        "\n",
        "We use Elasticsearch for indexing, and retrieving top-1000 answers per query in order to build the data for focusing on re-ranking."
      ],
      "metadata": {
        "id": "LLtfeazSuo7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## installing libraries for Elasticsearch and running Elasticsearch deamon"
      ],
      "metadata": {
        "id": "3pPjwZcC_4tQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install elasticsearch==7.14.0\n",
        "!apt install default-jdk > /dev/null"
      ],
      "metadata": {
        "id": "5tk9NFz5ustn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "importing libraries"
      ],
      "metadata": {
        "id": "fcrHfqVH_-Jb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import os\n",
        "  import elasticsearch\n",
        "  from elasticsearch import Elasticsearch\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  import sys\n",
        "  import json\n",
        "  from ast import literal_eval\n",
        "  from tqdm import tqdm \n",
        "  import datetime\n",
        "  from elasticsearch import helpers\n",
        "  \n",
        "except Exception as e:\n",
        "  print(f\"error: {e}\")"
      ],
      "metadata": {
        "id": "TE1PeLqR_9fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading elasticsearch software"
      ],
      "metadata": {
        "id": "lzZC9BGSACqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.0.0-linux-x86_64.tar.gz -q\n",
        "!tar -xzf elasticsearch-7.0.0-linux-x86_64.tar.gz\n",
        "!chown -R daemon:daemon elasticsearch-7.0.0"
      ],
      "metadata": {
        "id": "AQqSjj0wAE9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Starting Elasticsearch daemon instance"
      ],
      "metadata": {
        "id": "cTQdyo6yAMMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "es_server = Popen(['elasticsearch-7.0.0/bin/elasticsearch'], \n",
        "                  stdout=PIPE, stderr=STDOUT,\n",
        "                  preexec_fn=lambda: os.setuid(1)  # as daemon\n",
        "                 )"
      ],
      "metadata": {
        "id": "QL7Z3jfhALWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "check if elasticsearch is loaded :)"
      ],
      "metadata": {
        "id": "3ZhM6bacASP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl localhost:9200"
      ],
      "metadata": {
        "id": "kPBMRFnkAUlV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b075c8a6-01e3-4a8b-d5ac-8ef914ce6538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\" : \"18c85f44f185\",\n",
            "  \"cluster_name\" : \"elasticsearch\",\n",
            "  \"cluster_uuid\" : \"250L5plyQeGy_Qx07k2CnA\",\n",
            "  \"version\" : {\n",
            "    \"number\" : \"7.0.0\",\n",
            "    \"build_flavor\" : \"default\",\n",
            "    \"build_type\" : \"tar\",\n",
            "    \"build_hash\" : \"b7e28a7\",\n",
            "    \"build_date\" : \"2019-04-05T22:55:32.697037Z\",\n",
            "    \"build_snapshot\" : false,\n",
            "    \"lucene_version\" : \"8.0.0\",\n",
            "    \"minimum_wire_compatibility_version\" : \"6.7.0\",\n",
            "    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n",
            "  },\n",
            "  \"tagline\" : \"You Know, for Search\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Elasticsearch util class"
      ],
      "metadata": {
        "id": "xY_XBMMoAjum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import elasticsearch\n",
        "from elasticsearch import helpers\n",
        "print(elasticsearch.__version__)\n",
        "print(elasticsearch.__versionstr__)\n",
        "class ElasticSearch:\n",
        "\tdef __init__(self):\n",
        "\t\t# configure elasticsearch\n",
        "\t\tconfig = {\n",
        "\t\t\t\"localhost\": 9200\n",
        "\t\t}\n",
        "\t\tself.es = elasticsearch.Elasticsearch([config, ], timeout=300)\n",
        "\t\tself.last_scroll_id = None\n",
        "\n",
        "\tdef create_index(self, name, mapping, replace=False):\n",
        "\t\tif replace:\n",
        "\t\t\tself.delete_index(name)\n",
        "\t\tprint(\"creating index, name: \", name)\n",
        "\t\tself.es.indices.create(index=name, body=mapping)\n",
        "\t\tprint(\"index created successfully, index name: \" + name)\n",
        "\n",
        "\tdef delete_index(self, name):\n",
        "\t\tprint(\"deleting index, name: \", name)\n",
        "\t\tself.es.indices.delete(index=name, ignore=[400, 404])\n",
        "\t\tprint(\"index deleted successfully, index name: \" + name)\n",
        "\n",
        "\tdef index(self, documents, index_name, is_bulk=False):\n",
        "\n",
        "\t\tif is_bulk:\n",
        "\t\t\ttry:\n",
        "\t\t\t\t# make the bulk call, and get a response\n",
        "\t\t\t\tresponse = helpers.bulk(self.es, documents)  # chunk_size=1000, request_timeout=200\n",
        "\t\t\t\tprint(\"\\nRESPONSE:\", response)\n",
        "\t\t\texcept Exception as e:\n",
        "\t\t\t\tprint(\"\\nERROR:\", e)\n",
        "\n",
        "\tdef search(self, index, body):\n",
        "\t\ttry:\n",
        "\t\t\t# make the bulk call, and get a response\n",
        "\t\t\treturn self.es.search(index=index, body=body)\n",
        "\t\texcept Exception as e:\n",
        "\t\t\tprint(\"\\nERROR:\", e)\n",
        "\n",
        "\tdef search_all_with_scorll(self, index, body):\n",
        "\t\ttry:\n",
        "\t\t\t# if 'size' in body:\n",
        "\t\t\t#     del body['size']\n",
        "\t\t\t#get all result ! append everything to it! append to hits[] maybe !\n",
        "\t\t\t# make the bulk call, and get a response'\n",
        "\t\t\tthere_is_next_page = False\n",
        "\n",
        "\t\t\tresp = self.es.search(\n",
        "\t\t\t\tindex=index,\n",
        "\t\t\t\tbody=body,\n",
        "\t\t\t\tscroll = '3m', # time value for search\n",
        "\t\t\t)\n",
        "\t\t\tself.last_scroll_id = resp['_scroll_id']\n",
        "\t\t\tif len(resp['hits']['hits'])>=10000:\n",
        "\t\t\t\tthere_is_next_page = True\n",
        "\t\t\twhile there_is_next_page:\n",
        "\t\t\t\tresp_scroll = self.es.scroll(\n",
        "\t\t\t\t\tscroll = '3m', # time value for search\n",
        "\t\t\t\t\tscroll_id=self.last_scroll_id,\n",
        "\t\t\t\t)\n",
        "\t\t\t\tself.last_scroll_id = resp_scroll['_scroll_id']\n",
        "\t\t\t\tresp['hits']['hits'].extend(resp_scroll['hits']['hits'])\n",
        "\t\t\t\tif len(resp_scroll['hits']['hits']) >=10000:\n",
        "\t\t\t\t\tthere_is_next_page = True\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tthere_is_next_page = False\n",
        "\n",
        "\t\t\tif there_is_next_page==False:\n",
        "\t\t\t\tself.last_scroll_id = None\n",
        "\t\t\t\treturn resp\n",
        "\t\t\t#if hits is zero then there is no new!\n",
        "\t\t\t# return\n",
        "\t\texcept Exception as e:\n",
        "\t\t\tprint(\"\\nERROR:\", e)\n",
        "\tdef get_with_id(self, index, id_):\n",
        "\t\ttry:\n",
        "\t\t\t# make the bulk call, and get a response\n",
        "\t\t\treturn self.es.get(index=index, id=id_)\n",
        "\t\texcept Exception as e:\n",
        "\t\t\tprint(\"\\nERROR:\", e)\n",
        "\tdef termvectors(self, index, body, id):\n",
        "\t\ttry:\n",
        "\t\t\t# make the bulk call, and get a response\n",
        "\t\t\treturn self.es.termvectors(index=index, body=body, id=id)\n",
        "\t\texcept Exception as e:\n",
        "\t\t\tprint(\"\\nERROR:\", e)"
      ],
      "metadata": {
        "id": "JlFtZSw0Anlg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6bb9aa9-082a-4fc3-9aff-11c7bbf5778d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7, 14, 0)\n",
            "7.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget https://www.dropbox.com/s/t5t2lmm30tvhvht/paragraph-level-mapping.json"
      ],
      "metadata": {
        "id": "Y8eoucZfBOS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mapping():\n",
        "  return json.loads(open(\"paragraph-level-mapping.json\").read())"
      ],
      "metadata": {
        "id": "yyeQNHVnAxkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_docs(index_name, application_in_training, docs_id_text_dict, bulk_size):\n",
        "  docs = []\n",
        "  for doc_id, doc_text in docs_id_text_dict.items():\n",
        "    doc = {\n",
        "\t\t\t\t\t\t\"_index\": index_name,\n",
        "\t\t\t\t\t\t\"_id\": doc_id,\n",
        "\t\t\t\t\t\t\"application_in_training\": application_in_training,\n",
        "\t\t\t\t\t\t\"content\": doc_text,\n",
        "      }\n",
        "    docs.append(doc)\n",
        "    if len(docs)>=bulk_size:\n",
        "      yield docs\n",
        "      docs = []\n",
        "  yield docs\n",
        "\n",
        "def indexing(index_name, application_in_training, replace_index, mapping, docs_id_text_dict, bulk_size = 500):\n",
        "  print(\"indexer run..  index_name: {}\", index_name)\n",
        "\n",
        "  es = ElasticSearch()\n",
        "  print(\"creating index mapping...\")\n",
        "  try:\n",
        "    es.create_index(index_name, mapping, replace=replace_index)\n",
        "  except Exception as e:\n",
        "    print(\"creating index error: \", e)\n",
        "    pass\n",
        "  print(\"index mapping created !\")\n",
        "  docs = get_docs(index_name, application_in_training, docs_id_text_dict, bulk_size)\n",
        "  for bulk_docs in docs:\n",
        "    print(\"indexing {} documents started...: \".format(bulk_size))\n",
        "    es.index(index_name=index_name, documents=bulk_docs, is_bulk=True)\n",
        "    print(\"all {} docs indexed :)\".format(bulk_size))\n",
        "    docs = []"
      ],
      "metadata": {
        "id": "8NJ1VBVcBZMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vTIV6Sh5FvTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### rank function"
      ],
      "metadata": {
        "id": "Cf6Y1YcoF0Vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def\trank(index_name, query_dict, qids, top_n, output_path):\n",
        "  report = {}\n",
        "  print(\"index_name: {}, query_dict: {}, qids: {}, output_path: {}\".format(index_name, query_dict, qids, output_path))\n",
        "  es = ElasticSearch()\n",
        "  field = \"content\"\n",
        "  f_w = open(output_path, \"w\")\n",
        "  cnt = 0\n",
        "  for query_id in qids:\n",
        "    report[query_id] = {\"count_of_retrieved_docs\": 0}\n",
        "    query_text  = query_dict[query_id]\n",
        "    cnt+=1\n",
        "    bool_query = {\n",
        "        \"size\": top_n,\n",
        "        \"query\": {\n",
        "            \"bool\": {\n",
        "                \"should\": [\n",
        "                    {\"match\": {'content': query_text.lower()}}\n",
        "                ],\n",
        "                \"must_not\": [\n",
        "                    {\"term\": {'_id': query_id}}\n",
        "                ]\n",
        "                , \"minimum_should_match\": 0,\n",
        "                \"boost\": 1.0\n",
        "            }\n",
        "        },\n",
        "\t\t\t\"_source\": [\n",
        "\t\t\t\t\"_id\",\n",
        "\t\t\t],\n",
        "    }\n",
        "    candidates = es.search(index=index_name, body=bool_query)\n",
        "    rank = 1\n",
        "    trec_out = \"\"\n",
        "    report[query_id][\"count_of_retrieved_docs\"] =  len(candidates['hits']['hits'])\n",
        "    for candidate in candidates['hits']['hits']:\n",
        "      document_id = candidate[\"_id\"]\n",
        "      score = candidate[\"_score\"]\n",
        "      # candidate_doc = candidate[\"_source\"]\n",
        "      line = \"{query_id} Q0 {document_id} {rank} {score} STANDARD\\n\".format(query_id=query_id,\n",
        "          document_id=document_id,\n",
        "          rank=rank,\n",
        "          score=score\n",
        "      )\n",
        "      # trec_out += line\n",
        "      f_w.write(line)\n",
        "      rank += 1\n",
        "  f_w.close()\n",
        "  es.es.transport.close()\n",
        "  return report"
      ],
      "metadata": {
        "id": "fGR-o9eRCZ5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## indexing collection-h "
      ],
      "metadata": {
        "id": "jhB6bxUbBoIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"collection_h\"\n",
        "docs_id_text_dict = dict(all_human_answerids)\n",
        "application_in_training = \"corpus\"\n",
        "replace_index = True #if index already exist, remove it first\n",
        "mapping = get_mapping()\n",
        "indexing(index_name, application_in_training, replace_index, mapping, docs_id_text_dict, bulk_size = 20000)"
      ],
      "metadata": {
        "id": "ixmckY95Bq-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5df5da5a-464c-4e35-d183-a53be5c11c51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "indexer run..  index_name: {} collection_h\n",
            "creating index mapping...\n",
            "deleting index, name:  collection_h\n",
            "index deleted successfully, index name: collection_h\n",
            "creating index, name:  collection_h\n",
            "index created successfully, index name: collection_h\n",
            "index mapping created !\n",
            "indexing 20000 documents started...: \n",
            "\n",
            "RESPONSE: (20000, [])\n",
            "all 20000 docs indexed :)\n",
            "indexing 20000 documents started...: \n",
            "\n",
            "RESPONSE: (20000, [])\n",
            "all 20000 docs indexed :)\n",
            "indexing 20000 documents started...: \n",
            "\n",
            "RESPONSE: (18546, [])\n",
            "all 20000 docs indexed :)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check the size of index now!"
      ],
      "metadata": {
        "id": "P10XOYQpEM2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl localhost:9200/_cat/indices?v"
      ],
      "metadata": {
        "id": "clpfMVXCEO4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "effce737-be90-4d13-cd2c-52338729d184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "health status index        uuid                   pri rep docs.count docs.deleted store.size pri.store.size\n",
            "yellow open   collection_h IT8JJ1IMRU-jYkIAx9Gq3A   1   1      55500            0     54.3mb         54.3mb\n",
            "yellow open   collection_c 7i14TubDRva6i_1gThJRUg   1   1      26884            0       50mb           50mb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## indexing collection-c "
      ],
      "metadata": {
        "id": "_orKM1FxEWWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"collection_c\"\n",
        "docs_id_text_dict = dict(all_chatgpt_answerids)\n",
        "application_in_training = \"corpus\"\n",
        "replace_index = True #if index already exist, remove it first\n",
        "mapping = get_mapping()\n",
        "indexing(index_name, application_in_training, replace_index, mapping, docs_id_text_dict, bulk_size = 20000)"
      ],
      "metadata": {
        "id": "coCnscVXEWWY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e2ade9e-278c-4ce6-eeeb-c5fcda6324a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "indexer run..  index_name: {} collection_c\n",
            "creating index mapping...\n",
            "deleting index, name:  collection_c\n",
            "index deleted successfully, index name: collection_c\n",
            "creating index, name:  collection_c\n",
            "index created successfully, index name: collection_c\n",
            "index mapping created !\n",
            "indexing 20000 documents started...: \n",
            "\n",
            "RESPONSE: (20000, [])\n",
            "all 20000 docs indexed :)\n",
            "indexing 20000 documents started...: \n",
            "\n",
            "RESPONSE: (6882, [])\n",
            "all 20000 docs indexed :)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl localhost:9200/_cat/indices?v"
      ],
      "metadata": {
        "id": "7skkoqgKEk5x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb3ff278-9eef-4136-ca99-4902b62f51e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "health status index        uuid                   pri rep docs.count docs.deleted store.size pri.store.size\n",
            "yellow open   collection_c VJqfPmFMReKFBuzR47s_XA   1   1      24387            0     48.6mb         48.6mb\n",
            "yellow open   collection_h IT8JJ1IMRU-jYkIAx9Gq3A   1   1      58546            0     82.8mb         82.8mb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## top-h (train/validation/test)"
      ],
      "metadata": {
        "id": "3eJ57EsGFALh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### top-1000-h train"
      ],
      "metadata": {
        "id": "FMNHdd1AFEEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment all of the below lines to generate the file! \n",
        "index_name = \"collection_h\"\n",
        "top_n = 1000\n",
        "split_name = \"train\"\n",
        "output_path = base_path + \"top_{}_h_{}.run\".format(top_n, split_name)\n",
        "report_dict = rank(index_name, query_dict, split_questions_ids_all[split_name], top_n, output_path)"
      ],
      "metadata": {
        "id": "IJAa1Tn1FGOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc187802-29db-4446-f1b0-dd74994a1606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the report and run file. It is important to the output of \"# of queries with 10 candidates:\" be zero, so for each query, at least 10 candidate exsit!"
      ],
      "metadata": {
        "id": "Ydm9zRJLgnkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"-----\\nstat on this run: \")\n",
        "print(\"# of queries: \", len(report_dict.keys()))\n",
        "count_of_retrieved_docs_list = [report_dict[item][\"count_of_retrieved_docs\"] for item in report_dict.keys()]\n",
        "print(\"# of queries with 0 candidate: \", len([item for item in count_of_retrieved_docs_list if item == 0]))\n",
        "print(\"# of queries with >=10 candidates: \", len([item for item in count_of_retrieved_docs_list if item >= 10]))\n",
        "print(\"# of queries with >=100 candidates: \", len([item for item in count_of_retrieved_docs_list if item >= 100]))\n",
        "print(\"# of queries with >=500 candidate: \", len([item for item in count_of_retrieved_docs_list if item >= 100]))\n",
        "print(\"# of queries with <1000 candidate: \", len([item for item in count_of_retrieved_docs_list if item < 1000]))\n",
        "average_of_candidate_doc_per_query = sum(count_of_retrieved_docs_list)/len(count_of_retrieved_docs_list)\n",
        "print(\"average_of_candidate_doc_per_query: \", average_of_candidate_doc_per_query)\n",
        "print(\"------------------\")\n",
        "#take a look on file: \n",
        "!tail -n 5 ./gdrive/MyDrive/ChatGPT-RetrievalQA/top_1000_h_train.run\n",
        "print(\"------------------\")\n",
        "#Check count of lines. (should be <= 16788 \\* 1000 = 16,788,000)\n",
        "!wc -l ./gdrive/MyDrive/ChatGPT-RetrievalQA/top_1000_h_train.run"
      ],
      "metadata": {
        "id": "xM7ggkmUgrZk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "136f3bfb-44ba-4cec-9ac9-6082e5689b20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----\n",
            "stat on this run: \n",
            "# of queries:  16788\n",
            "# of queries with 0 candidate:  0\n",
            "# of queries with >=10 candidates:  16788\n",
            "# of queries with >=100 candidates:  16783\n",
            "# of queries with >=500 candidate:  16783\n",
            "# of queries with <1000 candidate:  27\n",
            "average_of_candidate_doc_per_query:  999.1733380986419\n",
            "------------------\n",
            "23935 Q0 5971_H_1 996 26.517561 STANDARD\n",
            "23935 Q0 10984_H_1 997 26.506844 STANDARD\n",
            "23935 Q0 13987_H_1 998 26.506844 STANDARD\n",
            "23935 Q0 12347_H_2 999 26.506145 STANDARD\n",
            "23935 Q0 11204_H_0 1000 26.5013 STANDARD\n",
            "------------------\n",
            "16774122 ./gdrive/MyDrive/ChatGPT-RetrievalQA/top_1000_h_train.run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### top-1000-h valid"
      ],
      "metadata": {
        "id": "kAFzbE5Cuxuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment all of the below lines to generate the file! \n",
        "index_name = \"collection_h\"\n",
        "top_n = 1000\n",
        "split_name = \"valid\"\n",
        "output_path = base_path + \"top_{}_h_{}.run\".format(top_n, split_name)\n",
        "report_dict = rank(index_name, query_dict, split_questions_ids_all[split_name], top_n, output_path)"
      ],
      "metadata": {
        "id": "53FJml2tuxuy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcdb34b0-4baa-4775-86c2-185b57dab459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the report and run file. It is important to the output of \"# of queries with 10 candidates:\" be zero, so for each query, at least 10 candidate exsit!"
      ],
      "metadata": {
        "id": "MSQ-xEveuxuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"-----\\nstat on this run: \")\n",
        "print(\"# of queries: \", len(report_dict.keys()))\n",
        "count_of_retrieved_docs_list = [report_dict[item][\"count_of_retrieved_docs\"] for item in report_dict.keys()]\n",
        "print(\"# of queries with 0 candidate: \", len([item for item in count_of_retrieved_docs_list if item == 0]))\n",
        "print(\"# of queries with >=10 candidates: \", len([item for item in count_of_retrieved_docs_list if item >= 10]))\n",
        "print(\"# of queries with >=100 candidates: \", len([item for item in count_of_retrieved_docs_list if item >= 100]))\n",
        "print(\"# of queries with >=500 candidate: \", len([item for item in count_of_retrieved_docs_list if item >= 100]))\n",
        "print(\"# of queries with <1000 candidate: \", len([item for item in count_of_retrieved_docs_list if item < 1000]))\n",
        "average_of_candidate_doc_per_query = sum(count_of_retrieved_docs_list)/len(count_of_retrieved_docs_list)\n",
        "print(\"average_of_candidate_doc_per_query: \", average_of_candidate_doc_per_query)\n",
        "print(\"------------------\")\n",
        "#take a look on file: \n",
        "!tail -n 5 ./gdrive/MyDrive/ChatGPT-RetrievalQA/top_1000_h_valid.run\n",
        "print(\"------------------\")\n",
        "#Check count of lines. \n",
        "!wc -l ./gdrive/MyDrive/ChatGPT-RetrievalQA/top_1000_h_valid.run"
      ],
      "metadata": {
        "id": "cxTpOxhGuxu0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "179f5664-5a33-4623-aa45-c4c2fa5326d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----\n",
            "stat on this run: \n",
            "# of queries:  606\n",
            "# of queries with 0 candidate:  0\n",
            "# of queries with >=10 candidates:  606\n",
            "# of queries with >=100 candidates:  606\n",
            "# of queries with >=500 candidate:  606\n",
            "# of queries with <1000 candidate:  1\n",
            "average_of_candidate_doc_per_query:  999.927392739274\n",
            "------------------\n",
            "23966 Q0 4904_H_2 996 28.89788 STANDARD\n",
            "23966 Q0 1481_H_0 997 28.896053 STANDARD\n",
            "23966 Q0 223_H_1 998 28.892103 STANDARD\n",
            "23966 Q0 9602_H_1 999 28.885115 STANDARD\n",
            "23966 Q0 7642_H_0 1000 28.884119 STANDARD\n",
            "------------------\n",
            "605956 ./gdrive/MyDrive/ChatGPT-RetrievalQA/top_1000_h_valid.run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### top-1000-h test"
      ],
      "metadata": {
        "id": "fYAidXXnn0IN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment all of the below lines to generate the file! \n",
        "index_name = \"collection_h\"\n",
        "top_n = 1000\n",
        "split_name = \"test\"\n",
        "output_path = base_path + \"top_{}_h_{}.run\".format(top_n, split_name)\n",
        "report_dict = rank(index_name, query_dict, split_questions_ids_all[split_name], top_n, output_path)"
      ],
      "metadata": {
        "id": "lUfy8UAxn0IP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9df0d14-31f3-41e7-c42b-b93a59160d7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the report and run file. It is important to the output of \"# of queries with 10 candidates:\" be zero, so for each query, at least 10 candidate exsit!"
      ],
      "metadata": {
        "id": "oGyJWSJ7n0IQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"-----\\nstat on this run: \")\n",
        "print(\"# of queries: \", len(report_dict.keys()))\n",
        "count_of_retrieved_docs_list = [report_dict[item][\"count_of_retrieved_docs\"] for item in report_dict.keys()]\n",
        "print(\"# of queries with 0 candidate: \", len([item for item in count_of_retrieved_docs_list if item == 0]))\n",
        "print(\"# of queries with >=10 candidates: \", len([item for item in count_of_retrieved_docs_list if item >= 10]))\n",
        "print(\"# of queries with >=100 candidates: \", len([item for item in count_of_retrieved_docs_list if item >= 100]))\n",
        "print(\"# of queries with >=500 candidate: \", len([item for item in count_of_retrieved_docs_list if item >= 100]))\n",
        "print(\"# of queries with <1000 candidate: \", len([item for item in count_of_retrieved_docs_list if item < 1000]))\n",
        "average_of_candidate_doc_per_query = sum(count_of_retrieved_docs_list)/len(count_of_retrieved_docs_list)\n",
        "print(\"average_of_candidate_doc_per_query: \", average_of_candidate_doc_per_query)\n",
        "print(\"------------------\")\n",
        "#take a look on file: \n",
        "!tail -n 5 ./gdrive/MyDrive/ChatGPT-RetrievalQA/top_1000_h_test.run\n",
        "print(\"------------------\")\n",
        "#Check count of lines. \n",
        "!wc -l ./gdrive/MyDrive/ChatGPT-RetrievalQA/top_1000_h_test.run"
      ],
      "metadata": {
        "id": "2Cj-Y5UYn0IR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e728416-e68a-4b57-c7c2-b0c5945f9bd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----\n",
            "stat on this run: \n",
            "# of queries:  6928\n",
            "# of queries with 0 candidate:  0\n",
            "# of queries with >=10 candidates:  6928\n",
            "# of queries with >=100 candidates:  6925\n",
            "# of queries with >=500 candidate:  6925\n",
            "# of queries with <1000 candidate:  12\n",
            "average_of_candidate_doc_per_query:  998.9672344110854\n",
            "------------------\n",
            "24321 Q0 4786_H_2 996 35.236233 STANDARD\n",
            "24321 Q0 3624_H_1 997 35.235703 STANDARD\n",
            "24321 Q0 6051_H_0 998 35.234554 STANDARD\n",
            "24321 Q0 21125_H_0 999 35.229797 STANDARD\n",
            "24321 Q0 8982_H_1 1000 35.2249 STANDARD\n",
            "------------------\n",
            "6920845 ./gdrive/MyDrive/ChatGPT-RetrievalQA/top_1000_h_test.run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## top-c (train/validation/test)"
      ],
      "metadata": {
        "id": "xn_dVeqoyNpl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### top-1000-c train"
      ],
      "metadata": {
        "id": "ID5kqIQbyNpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment all of the below lines to generate the file! \n",
        "index_name = \"collection_c\"\n",
        "top_n = 1000\n",
        "split_name = \"train\"\n",
        "output_path = base_path + \"top_{}_c_{}.run\".format(top_n, split_name)\n",
        "report_dict = rank(index_name, query_dict, split_questions_ids_all[split_name], top_n, output_path)"
      ],
      "metadata": {
        "id": "KNFuOm6ZyNpr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66102501-fd2e-4a72-e3e6-95d5de04ae04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the report and run file. It is important to the output of \"# of queries with 10 candidates:\" be zero, so for each query, at least 10 candidate exsit!"
      ],
      "metadata": {
        "id": "lEYleElfyNpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"-----\\nstat on this run: \")\n",
        "print(\"# of queries: \", len(report_dict.keys()))\n",
        "count_of_retrieved_docs_list = [report_dict[item][\"count_of_retrieved_docs\"] for item in report_dict.keys()]\n",
        "print(\"# of queries with 0 candidate: \", len([item for item in count_of_retrieved_docs_list if item == 0]))\n",
        "print(\"# of queries with >=10 candidates: \", len([item for item in count_of_retrieved_docs_list if item >= 10]))\n",
        "print(\"# of queries with >=100 candidates: \", len([item for item in count_of_retrieved_docs_list if item >= 100]))\n",
        "print(\"# of queries with >=500 candidate: \", len([item for item in count_of_retrieved_docs_list if item >= 100]))\n",
        "print(\"# of queries with <1000 candidate: \", len([item for item in count_of_retrieved_docs_list if item < 1000]))\n",
        "average_of_candidate_doc_per_query = sum(count_of_retrieved_docs_list)/len(count_of_retrieved_docs_list)\n",
        "print(\"average_of_candidate_doc_per_query: \", average_of_candidate_doc_per_query)\n",
        "print(\"------------------\")\n",
        "#take a look on file: \n",
        "!tail -n 5 ./gdrive/MyDrive/ChatGPT-RetrievalQA/top_1000_c_train.run\n",
        "print(\"------------------\")\n",
        "#Check count of lines. (should be <= 16788 \\* 1000 = 16,788,000)\n",
        "!wc -l ./gdrive/MyDrive/ChatGPT-RetrievalQA/top_1000_c_train.run"
      ],
      "metadata": {
        "id": "qAcb0TeEyNpv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9952aab4-16c0-4e47-eafa-f85402110d51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----\n",
            "stat on this run: \n",
            "# of queries:  16788\n",
            "# of queries with 0 candidate:  0\n",
            "# of queries with >=10 candidates:  16788\n",
            "# of queries with >=100 candidates:  16784\n",
            "# of queries with >=500 candidate:  16784\n",
            "# of queries with <1000 candidate:  35\n",
            "average_of_candidate_doc_per_query:  998.8104598522755\n",
            "------------------\n",
            "23935 Q0 1070_C_0 996 17.58851 STANDARD\n",
            "23935 Q0 6746_C_0 997 17.587818 STANDARD\n",
            "23935 Q0 4025_C_0 998 17.583414 STANDARD\n",
            "23935 Q0 22790_C_0 999 17.580814 STANDARD\n",
            "23935 Q0 2713_C_0 1000 17.578367 STANDARD\n",
            "------------------\n",
            "16768030 ./gdrive/MyDrive/ChatGPT-RetrievalQA/top_1000_c_train.run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### top-1000-c valid"
      ],
      "metadata": {
        "id": "a7AttegoyNpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment all of the below lines to generate the file! \n",
        "index_name = \"collection_c\"\n",
        "top_n = 1000\n",
        "split_name = \"valid\"\n",
        "output_path = base_path + \"top_{}_c_{}.run\".format(top_n, split_name)\n",
        "report_dict = rank(index_name, query_dict, split_questions_ids_all[split_name], top_n, output_path)"
      ],
      "metadata": {
        "id": "tJntVTWpyNpz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c8806e9-bef6-42de-f9fe-f32e3febf218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the report and run file. It is important to the output of \"# of queries with 10 candidates:\" be zero, so for each query, at least 10 candidate exsit!"
      ],
      "metadata": {
        "id": "HYsCkMQEyNp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"-----\\nstat on this run: \")\n",
        "print(\"# of queries: \", len(report_dict.keys()))\n",
        "count_of_retrieved_docs_list = [report_dict[item][\"count_of_retrieved_docs\"] for item in report_dict.keys()]\n",
        "print(\"# of queries with 0 candidate: \", len([item for item in count_of_retrieved_docs_list if item == 0]))\n",
        "print(\"# of queries with >=10 candidates: \", len([item for item in count_of_retrieved_docs_list if item >= 10]))\n",
        "print(\"# of queries with >=100 candidates: \", len([item for item in count_of_retrieved_docs_list if item >= 100]))\n",
        "print(\"# of queries with >=500 candidate: \", len([item for item in count_of_retrieved_docs_list if item >= 100]))\n",
        "print(\"# of queries with <1000 candidate: \", len([item for item in count_of_retrieved_docs_list if item < 1000]))\n",
        "average_of_candidate_doc_per_query = sum(count_of_retrieved_docs_list)/len(count_of_retrieved_docs_list)\n",
        "print(\"average_of_candidate_doc_per_query: \", average_of_candidate_doc_per_query)\n",
        "print(\"------------------\")\n",
        "#take a look on file: \n",
        "!tail -n 5 ./gdrive/MyDrive/ChatGPT-RetrievalQA/top_1000_c_valid.run\n",
        "print(\"------------------\")\n",
        "#Check count of lines. \n",
        "!wc -l ./gdrive/MyDrive/ChatGPT-RetrievalQA/top_1000_c_valid.run"
      ],
      "metadata": {
        "id": "9YGJXN-9yNp3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a857e497-1ffb-42af-df85-7c0a75524634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----\n",
            "stat on this run: \n",
            "# of queries:  606\n",
            "# of queries with 0 candidate:  0\n",
            "# of queries with >=10 candidates:  606\n",
            "# of queries with >=100 candidates:  606\n",
            "# of queries with >=500 candidate:  606\n",
            "# of queries with <1000 candidate:  2\n",
            "average_of_candidate_doc_per_query:  999.6584158415842\n",
            "------------------\n",
            "23966 Q0 9400_C_0 996 19.34834 STANDARD\n",
            "23966 Q0 21618_C_0 997 19.347855 STANDARD\n",
            "23966 Q0 13383_C_0 998 19.347305 STANDARD\n",
            "23966 Q0 17374_C_2 999 19.342844 STANDARD\n",
            "23966 Q0 15085_C_0 1000 19.341434 STANDARD\n",
            "------------------\n",
            "605793 ./gdrive/MyDrive/ChatGPT-RetrievalQA/top_1000_c_valid.run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### top-1000-c test"
      ],
      "metadata": {
        "id": "77WCPjZbyNp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment all of the below lines to generate the file! \n",
        "index_name = \"collection_c\"\n",
        "top_n = 1000\n",
        "split_name = \"test\"\n",
        "output_path = base_path + \"top_{}_c_{}.run\".format(top_n, split_name)\n",
        "report_dict = rank(index_name, query_dict, split_questions_ids_all[split_name], top_n, output_path)"
      ],
      "metadata": {
        "id": "WHhoaYAhyNp5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46f33673-f84e-435a-cf5a-4e464f6c4b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the report and run file. It is important to the output of \"# of queries with 10 candidates:\" be zero, so for each query, at least 10 candidate exsit!"
      ],
      "metadata": {
        "id": "l9Vo1EK-yNp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"-----\\nstat on this run: \")\n",
        "print(\"# of queries: \", len(report_dict.keys()))\n",
        "count_of_retrieved_docs_list = [report_dict[item][\"count_of_retrieved_docs\"] for item in report_dict.keys()]\n",
        "print(\"# of queries with 0 candidate: \", len([item for item in count_of_retrieved_docs_list if item == 0]))\n",
        "print(\"# of queries with >=10 candidates: \", len([item for item in count_of_retrieved_docs_list if item >= 10]))\n",
        "print(\"# of queries with >=100 candidates: \", len([item for item in count_of_retrieved_docs_list if item >= 100]))\n",
        "print(\"# of queries with >=500 candidate: \", len([item for item in count_of_retrieved_docs_list if item >= 100]))\n",
        "print(\"# of queries with <1000 candidate: \", len([item for item in count_of_retrieved_docs_list if item < 1000]))\n",
        "average_of_candidate_doc_per_query = sum(count_of_retrieved_docs_list)/len(count_of_retrieved_docs_list)\n",
        "print(\"average_of_candidate_doc_per_query: \", average_of_candidate_doc_per_query)\n",
        "print(\"------------------\")\n",
        "#take a look on file: \n",
        "!tail -n 5 ./gdrive/MyDrive/ChatGPT-RetrievalQA/top_1000_c_test.run\n",
        "print(\"------------------\")\n",
        "#Check count of lines. \n",
        "!wc -l ./gdrive/MyDrive/ChatGPT-RetrievalQA/top_1000_c_test.run"
      ],
      "metadata": {
        "id": "GMcvUwbgyNp8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4f05a3e-8524-4f90-d3b2-520f530ab367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----\n",
            "stat on this run: \n",
            "# of queries:  6928\n",
            "# of queries with 0 candidate:  0\n",
            "# of queries with >=10 candidates:  6928\n",
            "# of queries with >=100 candidates:  6924\n",
            "# of queries with >=500 candidate:  6924\n",
            "# of queries with <1000 candidate:  18\n",
            "average_of_candidate_doc_per_query:  998.5010103926097\n",
            "------------------\n",
            "24321 Q0 8195_C_0 996 22.96967 STANDARD\n",
            "24321 Q0 8704_C_0 997 22.96967 STANDARD\n",
            "24321 Q0 9207_C_0 998 22.969248 STANDARD\n",
            "24321 Q0 19730_C_0 999 22.963724 STANDARD\n",
            "24321 Q0 16679_C_0 1000 22.961594 STANDARD\n",
            "------------------\n",
            "6917615 ./gdrive/MyDrive/ChatGPT-RetrievalQA/top_1000_c_test.run\n"
          ]
        }
      ]
    }
  ]
}